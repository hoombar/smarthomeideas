<!doctype html>
<html lang="en-gb">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <title>Smart Doorbell descriptions // Smart Home Ideas</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.142.0">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="John Doe" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.c70dd64245d43f7a510b498231733c7f093f88d8f3f85be754027cde34eac18d.css" />
    

    
    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Smart Doorbell descriptions">
  <meta name="twitter:description" content="Note: This is generated from a transcript from one of my YouTube videos
Introduction Elevate your smart home doorbell experience with a truly innovative integration: LLM Vision. This powerful tool allows your Home Assistant setup to “see” and describe who is at your door using advanced AI Vision. Imagine hearing “A devilishly handsome, definitely not middle-aged man is at the door” instead of a generic chime.
While it might seem like a novelty at first, the practical utility of this feature quickly becomes apparent. No more wondering “Ding Dong, they have already gone” or “Ding Dong, check the camera, their face is hidden.” This integration provides immediate, descriptive insights, making your smart home even more intelligent and responsive.">

    <meta property="og:url" content="http://localhost:1313/posts/smart-doorbell-descriptions/">
  <meta property="og:site_name" content="Smart Home Ideas">
  <meta property="og:title" content="Smart Doorbell descriptions">
  <meta property="og:description" content="Note: This is generated from a transcript from one of my YouTube videos
Introduction Elevate your smart home doorbell experience with a truly innovative integration: LLM Vision. This powerful tool allows your Home Assistant setup to “see” and describe who is at your door using advanced AI Vision. Imagine hearing “A devilishly handsome, definitely not middle-aged man is at the door” instead of a generic chime.
While it might seem like a novelty at first, the practical utility of this feature quickly becomes apparent. No more wondering “Ding Dong, they have already gone” or “Ding Dong, check the camera, their face is hidden.” This integration provides immediate, descriptive insights, making your smart home even more intelligent and responsive.">
  <meta property="og:locale" content="en_gb">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-07-23T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-07-23T00:00:00+00:00">


  </head>
  <body>
    <header class="app-header">
      <a href="/"><img class="app-header-avatar" src="/images/logo.png" alt="John Doe" /></a>
      <span class="app-header-title">Smart Home Ideas</span>
      <p>I&#39;m on a mission to make everyone as passionate about smart homes as I am.</p>
      <div class="app-header-social">
        
          <a href="https://www.youtube.com/@BensSmartHomeIdeas" target="_blank" rel="noreferrer noopener me">
            <svg class="icon icon-brand-youtube" viewBox="0 0 24 24" fill="currentColor"><title>YouTube</title><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Smart Doorbell descriptions</h1>
      <div class="post-meta">
        <div>
          <svg class="icon icon-calendar" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>calendar</title><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>
          Jul 23, 2025
        </div>
        <div>
          <svg class="icon icon-clock" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><title>clock</title><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>
          6 min read
        </div>
      </div>
    </header>
    <div class="post-content">
      <p>Note: <em>This is generated from a transcript from one of my <a href="https://www.youtube.com/@BensSmartHomeIdeas">YouTube videos</a></em></p>
<hr>
<h2 id="introduction">Introduction</h2>
<p>Elevate your smart home doorbell experience with a truly innovative integration: LLM Vision. This powerful tool allows your Home Assistant setup to &ldquo;see&rdquo; and describe who is at your door using advanced AI Vision. Imagine hearing &ldquo;A devilishly handsome, definitely not middle-aged man is at the door&rdquo; instead of a generic chime.</p>
<p>While it might seem like a novelty at first, the practical utility of this feature quickly becomes apparent. No more wondering &ldquo;Ding Dong, they have already gone&rdquo; or &ldquo;Ding Dong, check the camera, their face is hidden.&rdquo; This integration provides immediate, descriptive insights, making your smart home even more intelligent and responsive.</p>
<div class="semantic-image-grid" style="display: flex; flex-wrap: wrap; gap: 10px; margin: 20px 0; justify-content: space-around;">
<img src="frame_6.0s_optimized.jpg" alt="Introduction & Live Demo demonstration at 6.0s" title="Introduction & Live Demo (6.0s)" style="width: calc(48% - 5px) !important; height: auto !important; object-fit: cover; border-radius: 4px; display: inline-block !important; margin: 3px !important;">
<img src="frame_36.0s_optimized.jpg" alt="Introduction & Live Demo demonstration at 36.0s" title="Introduction & Live Demo (36.0s)" style="width: calc(48% - 5px) !important; height: auto !important; object-fit: cover; border-radius: 4px; display: inline-block !important; margin: 3px !important;">
<img src="frame_63.0s_optimized.jpg" alt="Google Cloud & Gemini API Setup demonstration at 63.0s" title="Google Cloud & Gemini API Setup (63.0s)" style="width: calc(48% - 5px) !important; height: auto !important; object-fit: cover; border-radius: 4px; display: inline-block !important; margin: 3px !important;">
<img src="frame_74.0s_optimized.jpg" alt="Google Cloud & Gemini API Setup demonstration at 74.0s" title="Google Cloud & Gemini API Setup (74.0s)" style="width: calc(48% - 5px) !important; height: auto !important; object-fit: cover; border-radius: 4px; display: inline-block !important; margin: 3px !important;">
</div>
<h2 id="google-cloud-and-gemini-api-setup">Google Cloud and Gemini API Setup</h2>
<p>To begin, you need to set up Gemini within Google Cloud. This process is straightforward and forms the foundation for your AI vision capabilities. Navigate to the Google Cloud Console and create a new project specifically for this integration.</p>
<p>Once your project is established, enable the Gemini API. This crucial step activates the AI functionalities required for the doorbell descriptions.</p>
<p>Next, obtain an API key from AI Studio. Visit AIStudio.google.com/app/apikey to generate your key. Ensure you select the Google Cloud project you just configured. Keep this API key accessible, as it will be needed shortly for the integration.</p>
<h2 id="llm-vision-integration-installation">LLM Vision Integration Installation</h2>
<p>The next step involves installing the LLM Vision integration itself. This is available through HACS, the Home Assistant Community Store. Comprehensive documentation for LLM Vision can be found at llmvision.gitbook.io, which also includes a blueprint for quick setup.</p>
<p>While a blueprint is available, an image-based approach was chosen for quicker processing compared to video. The installation process is efficient: first, install it from HACS like any other custom integration. After installation, restart Home Assistant.</p>
<p><img src="frame_105.0s_optimized.jpg" alt="Home Assistant Integration Installation demonstration at 105.0s"></p>
<p>Following the restart, you can install LLM Vision as a standard integration directly through the Home Assistant interface. During this setup, paste the API key obtained from AI Studio and select Google as your provider.</p>
<h2 id="privacy-considerations">Privacy Considerations</h2>
<p>Before proceeding, it is important to address privacy concerns. Some users may be hesitant about images being sent to the cloud, given that this is a remote LLM and not hosted locally. This means images are uploaded to Google servers for processing.</p>
<p>In a typical setup, this concern can be mitigated. For instance, if children are not expected to ring the doorbell, their images would not be captured. The automation can be configured to trigger only when the doorbell button is pressed, not merely when motion is detected in front of the camera, further enhancing privacy control.</p>
<h2 id="integrating-llm-vision-into-home-assistant-automation">Integrating LLM Vision into Home Assistant Automation</h2>
<p>The real power of LLM Vision comes to life when integrated into your Home Assistant automations. An existing automation might already capture a picture from your video doorbell and send a notification with the image to your phone when the button is pressed. This automation could also announce the doorbell ring throughout the house on various Google Home devices, which is useful if you are in another part of the house.</p>
<p>The goal is to enhance this existing automation by adding the capability to describe what the doorbell camera sees. The core of this functionality is the <code>llmvision.image_analyzer</code> action, provided by the integration.</p>
<p><img src="frame_181.0s_optimized.jpg" alt="Automation: Image Analysis Action demonstration at 181.0s"></p>
<p>The configuration for this action uses specific parameters for optimal results. The <code>max_tokens</code> parameter is set to 50 to ensure concise responses, with a token roughly equating to a word. The <code>temperature</code> is set to 0.2 for more consistent results, as values closer to 0 yield more precise outputs, while values closer to 1 encourage more creative responses. The Gemini 2.0 Flash model is utilized, primarily for its effectiveness and cost-free nature.</p>
<h2 id="prompt-engineering-for-ai-vision">Prompt Engineering for AI Vision</h2>
<p>The most fascinating aspect of this setup is prompt engineering. This is where you instruct the AI precisely what to look for and how to respond. A carefully crafted prompt can handle various common scenarios effectively.</p>
<p>Consider this example prompt, which has yielded excellent results: &ldquo;This is a picture from a video doorbell. If there is nobody there say they have already gone and nothing else. Otherwise if they&rsquo;re walking away say they have already gone and nothing else. Otherwise if they&rsquo;re faces hidden say check the camera, they&rsquo;re faces hidden and nothing else. Otherwise if none of the above true then say a adjective, man slash woman who looks like famous actor which I thought was quite fun. Holding whatever they&rsquo;re holding is at the door.&rdquo;</p>
<p><img src="frame_315.0s_optimized.jpg" alt="Automation: Prompt Engineering demonstration at 315.0s"></p>
<p>Being explicit with phrases like &ldquo;and nothing else&rdquo; prevents the AI from generating overly long or multiple responses. This approach is particularly effective for common doorbell interactions. People often ring and immediately depart, perhaps dropping off a package or being in a hurry.</p>
<p>Additionally, the prompt accounts for situations where a person&rsquo;s face might be obscured by a hood or mask, providing valuable information before you open the door. The results have been surprisingly accurate and entertaining. After some testing, the prompt was tweaked from consistently identifying a &ldquo;middle-aged man&rdquo; to now humorously stating &ldquo;I look like Matt Damon.&rdquo; This personalized touch has become a favorite feature of the smart home setup, transforming a simple doorbell announcement into a descriptive and useful message.</p>
<h2 id="customization-and-community-engagement">Customization and Community Engagement</h2>
<p>If you are considering implementing this for your own smart home, it is highly recommended to start with a basic setup. From there, you can fine-tune the prompts to align with your specific needs and preferences. You might desire more detailed descriptions, or perhaps you prefer the AI to focus on particular elements like packages or uniforms.</p>
<p><img src="frame_350.0s_optimized.jpg" alt="Benefits &amp; Customization demonstration at 350.0s"></p>
<p>Consider experimenting with different creative prompts to see what unique descriptions you can generate. Share your innovative prompt ideas in the comments below.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Integrating LLM Vision with your smart doorbell and Home Assistant offers a significant upgrade to your smart home&rsquo;s capabilities. By leveraging AI Vision, you gain descriptive, real-time insights into who is at your door, enhancing both convenience and security. The setup process, from Google Cloud configuration to prompt engineering, is manageable and highly customizable. This innovative approach transforms a simple doorbell ring into an intelligent, informative interaction, making your smart home truly smarter.</p>
<h1 id="links">Links:</h1>
<ul>
<li></li>
</ul>
<h1 id="video">Video</h1>
<p>You can watch the full video on YouTube here:

    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/uuid-link?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>
</p>
<h1 id="transcript">Transcript</h1>
<h1 id="support-me-to-keep-making-videos">Support me to keep making videos</h1>
<figure class="float-right"><a href="https://ko-fi.com/smarthomeideas"><img src="/img/ko-fi-stamp.png"
    alt="Ko-Fi" width="300"></a>
</figure>

<p>If you like the work I&rsquo;m doing, please drop a like on the video, or consider subscribing to the channel.</p>
<p>In case you&rsquo;re in a particularly generous mood, you can fund my next cup of coffee over on <a href="https://ko-fi.com/smarthomeideas">Ko-Fi</a></p>
<p>The links from some of my videos are affiliate links, which means I get a small kickback at no extra cost to you. It just means that the affiliate knows the traffic came from me.</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
